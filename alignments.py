import os
import xml.etree.ElementTree as ET
import re
from tqdm import tqdm


def split_align_file_docs(sent_align_path, word_align_path, split_dir):
    """
    Split the word alignment file into smaller files 
    each corresponding to one europarl file.

    Parameters
    ----------
    sent_align_path : str
        Xml file containing sentence alignments of the corpora.
    word_align_path : str
        File containing the word alignments for every sentence pair.
    split_dir : str
        Directory to save split files to.
    """

    tree = ET.parse(sent_align_path)
    docs = tree.iter(tag="linkGrp")
    with open(word_align_path) as word_align_file:
        for doc in tqdm(docs):
            fn = doc.attrib["fromDoc"][3:-7]
            links = list(doc.iter(tag="link"))
            num_sents = len(links)
            out_path = os.path.join(split_dir, fn)
            with open(out_path, "w") as out_file:
                for i, line in enumerate(word_align_file):
                    out_file.write(line)
                    if i == num_sents - 1:
                        break

def intersection_alignment(src2tgt_dir, tgt2src_dir, intersection_dir):
    """
    Get intersection of word alignments for two directions.

    Parameters
    ----------
    src2tgt_dir : str
        Directory containing alignments in one direction.
    tgt2src_dir : str
        Directory containing alignments in other direction.
    intersection_dir : str
        Directory to save intersection to.
    """

    fns = os.listdir(src2tgt_dir)
    fns_rev = os.listdir(tgt2src_dir)
    fns = [fn for fn in fns if fn in fns_rev]

    for fn in fns:
        src2tgt_path = os.path.join(src2tgt_dir, fn)
        tgt2src_path = os.path.join(tgt2src_dir, fn)
        intersection_path = os.path.join(intersection_dir, fn)
        with open(src2tgt_path) as s2t_file, \
                open(tgt2src_path) as t2s_file, \
                open(intersection_path, "w") as int_file:
            for s2t_line, t2s_line in zip(s2t_file, t2s_file):
                s2t = s2t_line.split()
                s2t = [a.split("-") for a in s2t]
                s2t = [(int(i),int(j)) for (i,j) in s2t]

                t2s = t2s_line.split()
                t2s = [a.split("-") for a in t2s]
                t2s = [(int(j),int(i)) for (i,j) in t2s]

                inter = [tup for tup in s2t if tup in t2s]
                inter = [str(i) + "-" + str(j) for (i,j) in inter]
                inter = " ".join(inter)
                int_file.write(inter)
                int_file.write("\n")


def split_aligned(aligned_path, comb1_path, comb2_path):
    """
    Split the aligned file generated by Gale-Church
    using the implementation from github.com/alvations/gachalign/.
    Save the aligned sentences to one file per language.

    Parameters
    ----------
    aligned_path : str
        Path of file containing aligned sentences for both languages.
    comb1_path : str
        Path to save sentences from first language to.
    comb2_path : str
        Path to save sentences from second language to.
    """
    fn_line = "tmp"
    
    with open(comb1_path, "w") as comb1, open(comb2_path, "w") as comb2:
        prev_line_hash = False
        for line in open(aligned_path):
            if line[0] == "#" and not prev_line_hash:
                comb1.write(line)
                comb2.write(line)
                prev_line_hash = True
            elif line[0] == "#" and prev_line_hash:
                continue
            else:
                line = line[:-1].lower()
                l1, l2 = line.split("\t")
                comb1.write(l1)
                comb1.write("\n")
                comb2.write(l2)
                comb2.write("\n")
                prev_line_hash = False


def rm_dok_names(comb_path, inds_path, out_path):
    """
    Take a combined file containing many europarl speeches.
    Remove the lines indicating a new speech,
    i.e. the ones beginning with "##############################".
    Also remove blank lines.
    For each speech, write the filename and the number
    of lines into a new file.

    Parameters
    ----------
    comb_path : str
        Original file containing speeches.
    inds_path : str
        File to save filenames and numbers of lines to.
    out_path : str
        File to save the speeches to.
    """

    with open(comb_path) as orig_file:
        with open(inds_path, "w") as inds_file, \
                open(out_path, "w") as out_file:
            curr_fn = None
            curr_num = 0
            for line in orig_file:
                if line[0] == "#":
                    if curr_fn is not None and curr_num != 0:
                        inds_file.write(curr_fn + " " + str(curr_num) + "\n")
                    curr_fn = line.split("#")[-1][:-1]
                    curr_num = 0
                else:
                    curr_num += 1
                    out_file.write(line)


def split_giza_results(giza_dir, out_dir):
    """
    Split the results of the giza run according to the europarl files.

    Parameters
    ----------
    giza_dir : str
        Path to directory containing giza output files.
    sent_inds_path : str
        File containing the europarl filenames and the
        corresponding number of sentence pairs.
    out_dir : str
        Path to write the resulting files to.
    """
    fns = os.listdir(giza_dir)
    fns = [fn for fn in fns if fn[:15]=="src_trg.dict.A3"]

    alg_lines = dict()

    num_reg = r"\(([0-9]+)\)"
    for fn in fns:
        giza_path = os.path.join(giza_dir, fn)
        line_ind = 0
        with open(giza_path) as f:
            for line in f:
                if line_ind == 0:
                    # line containing information about sentence pair
                    match = re.search(num_reg, line)
                    num = int(match.group(1))
                    line_ind = 1
                elif line_ind == 1:
                    # line containing target language text
                    alg_lines[num] = line[:-1]
                    line_ind = 2
                else:
                    alg_lines[num] = (alg_lines[num], line[:-1])
                    line_ind = 0
                
    fn = "tmp"
    for ind in sorted(alg_lines.keys()):
        out_path = os.path.join(out_dir, fn)
        line_trg, line_src = alg_lines[ind]
        if line_trg[0] == "#":
            fn = line_trg[30:-1]
            wc_src = 0
            wc_trg = 0
            continue
        word_alg = line_src.split(" })")
        if word_alg[-1].strip() == "":
            word_alg = word_alg[:-1]
        word_alg = [s.split(" ({") for s in word_alg]
        alg_line = ""
        for i, (word, inds) in enumerate(word_alg):
            if i == 0:
                #ignore NULL word
                continue
            inds = inds.split()
            for ind in inds:
                ind_trg = str(wc_trg + int(ind))
                ind_src = str(wc_src + i)
                alg_line += ind_src + "-" + ind_trg + " "
        alg_line += "\n"
        with open(out_path, "a") as out_file:
            out_file.write(alg_line)

        wc_src += len(word_alg) - 1
        wc_trg += len(line_trg.strip().split())
