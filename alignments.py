import os
import xml.etree.ElementTree as ET
import re
from tqdm import tqdm


def split_align_file_docs(sent_align_path, word_align_path, split_dir):
    """
    Split the word alignment file into smaller files 
    each corresponding to one europarl file.

    Parameters
    ----------
    sent_align_path : str
        Xml file containing sentence alignments of the corpora.
    word_align_path : str
        File containing the word alignments for every sentence pair.
    split_dir : str
        Directory to save split files to.
    """

    tree = ET.parse(sent_align_path)
    docs = tree.iter(tag="linkGrp")
    with open(word_align_path) as word_align_file:
        #align_lines = word_align_file.readlines()
        for doc in tqdm(docs):
            fn = doc.attrib["fromDoc"][3:-7]
            links = list(doc.iter(tag="link"))
            num_sents = len(links)
            #curr_lines = align_lines[:num_sents]
            out_path = os.path.join(split_dir, fn)
            with open(out_path, "w") as out_file:
                for i, line in enumerate(word_align_file):
                    out_file.write(line)
                    if i == num_sents - 1:
                        break

#split_align_file_docs("/home/johann/Studium/IM/data/Europarl/smt/de-en/bitext.xml",
#                      "/home/johann/Studium/IM/data/Europarl/smt/de-en/model/aligned.intersection",
#                      "/home/johann/Studium/IM/data/europarl/alignments/en_full_intersection")

def intersection_alignment(src2tgt_path, tgt2src_path, intersection_path):
    """
    Get intersection of word alignments for two directions.

    Parameters
    ----------
    src2tgt_path : str
        Alignment file in one direction.
    tgt2src_path : str
        Alignment file in other direction.
    intersection_path : str
        File to save intersection to.
    """

    with open(src2tgt_path) as s2t_file, \
            open(tgt2src_path) as t2s_file, \
            open(intersection_path, "w") as int_file:
        for s2t_line, t2s_line in zip(s2t_file, t2s_file):
            s2t = s2t_line.split()
            s2t = [a.split("-") for a in s2t]
            s2t = [(int(i),int(j)) for (i,j) in s2t]

            t2s = t2s_line.split()
            t2s = [a.split("-") for a in t2s]
            t2s = [(int(i),int(j)) for (i,j) in t2s]

            inter = [tup for tup in s2t if tup in t2s]
            inter = [str(i) + "-" + str(j) for (i,j) in inter]
            inter = " ".join(inter)
            int_file.write(inter)
            int_file.write("\n")


#intersection_alignment("/home/johann/Studium/IM/data/Europarl/smt/de-en/model/aligned.srctotgt", 
#        "/home/johann/Studium/IM/data/Europarl/smt/de-en/model/aligned.tgttosrc", 
#        "/home/johann/Studium/IM/data/Europarl/smt/de-en/model/aligned.intersection")


#def giza_prepare(lang1_dir, lang2_dir, comb1_path, comb2_path):
#    """
#    Write the texts for two languages in one file each,
#    such that the documents line up.
#    Also saves the filenames and the number of lines per document
#    to an extra file, so that the documents can be recovered later.
#
#    Parameters
#    ----------
#    lang1_dir : str
#        Path to directory containing txt files for first lanugage.
#    lang2_dir : str
#        Path to directory containing txt files for second language.
#    comb1_path : str
#        Path to save output for first language.
#    comb2_path : str
#        You get the idea.
#    """
#
#    fns1 = os.listdir(lang1_dir)
#    fns2 = os.listdir(lang2_dir)
#    common_fns = [fn for fn in fns1 if fn in fns2]
#    comb1_inds_path = comb1_path + "inds"
#    comb2_inds_path = comb2_path + "inds"
#
#    with open(comb1_path, "w") as comb1, open(comb2_path, "w") as comb2,\
#            open(comb1_inds_path, "w") as inds1, open(comb2_inds_path, "w") as inds2:
#        for fn in common_fns:
#            path1 = os.path.join(lang1_dir, fn)
#            comb1.write("##############################" + fn + "\n")
#            with open(path1) as f1:
#                lines = f1.readlines()
#                for line in lines:
#                    comb1.write(line)
#            inds1.write(fn + " " + str(len(lines)) + "\n")
#            
#            path2 = os.path.join(lang2_dir, fn)
#            comb2.write("##############################" + fn + "\n")
#            with open(path2) as f2:
#                lines = f2.readlines()
#                for line in lines:
#                    comb2.write(line)
#            inds2.write(fn + " " + str(len(lines)) + "\n")

#giza_prepare("/home/johann/Studium/IM/data/txt/cs_trans",
#             "/home/johann/Studium/IM/data/txt/de",
#             "/home/johann/Studium/IM/data/txt/comb2/cs_comb.txt",
#             "/home/johann/Studium/IM/data/txt/comb2/de_comb.txt")

def split_aligned(aligned_path, comb1_path, comb2_path):
    """
    Split the aligned file generated by Gale-Church
    using the implementation from github.com/alvations/gachalign/.
    Save the aligned sentences to one file per language.

    Parameters
    ----------
    aligned_path : str
        Path of file containing aligned sentences for both languages.
    comb1_path : str
        Path to save sentences from first language to.
    comb2_path : str
        Path to save sentences from second language to.
    """
    fn_line = "tmp"
    
    with open(comb1_path, "w") as comb1, open(comb2_path, "w") as comb2:
        prev_line_hash = False
        for line in open(aligned_path):
            if line[0] == "#" and not prev_line_hash:
                comb1.write(line)
                comb2.write(line)
                prev_line_hash = True
            elif line[0] == "#" and prev_line_hash:
                continue
            else:
                line = line[:-1]
                l1, l2 = line.split("\t")
                comb1.write(l1)
                comb1.write("\n")
                comb2.write(l2)
                comb2.write("\n")
                prev_line_hash = False
#split_aligned("/data/europarl/common/sent_aligned/de_en.txt",
#              "/data/europarl/common/sent_aligned/de_en4/de_comb.txt",
#              "/data/europarl/common/sent_aligned/de_en4/en_comb.txt")

def rm_dok_names(comb_path, inds_path, out_path):
    """
    Take a combined file containing many europarl speeches.
    Remove the lines indicating a new speech,
    i.e. the ones beginning with "##############################".
    Also remove blank lines.
    For each speech, write the filename and the number
    of lines into a new file.

    Parameters
    ----------
    comb_path : str
        Original file containing speeches.
    inds_path : str
        File to save filenames and numbers of lines to.
    out_path : str
        File to save the speeches to.
    """

    with open(comb_path) as orig_file:
        with open(inds_path, "w") as inds_file, \
                open(out_path, "w") as out_file:
            curr_fn = None
            curr_num = 0
            for line in orig_file:
                #if line.strip() == "":
                #    continue
                if line[0] == "#":
                    if curr_fn is not None and curr_num != 0:
                        inds_file.write(curr_fn + " " + str(curr_num) + "\n")
                    curr_fn = line.split("#")[-1][:-1]
                    curr_num = 0
                else:
                    curr_num += 1
                    out_file.write(line)


rm_dok_names("/data/europarl/common/sent_aligned/de_en4/en_comb.txt", 
             "/data/europarl/common/sent_aligned/de_en4/en_sent_inds.txt",
             "/data/europarl/common/sent_aligned/de_en4/en_no_fn.txt")
rm_dok_names("/data/europarl/common/sent_aligned/de_en4/de_comb.txt", 
             "/data/europarl/common/sent_aligned/de_en4/de_sent_inds.txt",
             "/data/europarl/common/sent_aligned/de_en4/de_no_fn.txt")
